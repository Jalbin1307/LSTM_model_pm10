{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "baking-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from ast import literal_eval\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "criminal-genesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type 0</th>\n",
       "      <th>type 1</th>\n",
       "      <th>type 2</th>\n",
       "      <th>type 3</th>\n",
       "      <th>type 4</th>\n",
       "      <th>type 5</th>\n",
       "      <th>type 6</th>\n",
       "      <th>type 7</th>\n",
       "      <th>type 8</th>\n",
       "      <th>type 9</th>\n",
       "      <th>...</th>\n",
       "      <th>type 30</th>\n",
       "      <th>type 31</th>\n",
       "      <th>type 32</th>\n",
       "      <th>type 33</th>\n",
       "      <th>type 34</th>\n",
       "      <th>type 35</th>\n",
       "      <th>type 36</th>\n",
       "      <th>type 37</th>\n",
       "      <th>type 38</th>\n",
       "      <th>type 39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>170</td>\n",
       "      <td>184</td>\n",
       "      <td>182</td>\n",
       "      <td>198</td>\n",
       "      <td>175</td>\n",
       "      <td>183</td>\n",
       "      <td>208</td>\n",
       "      <td>212</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>37</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "      <td>69</td>\n",
       "      <td>52</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "      <td>74</td>\n",
       "      <td>90</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>63</td>\n",
       "      <td>64</td>\n",
       "      <td>61</td>\n",
       "      <td>57</td>\n",
       "      <td>72</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>96</td>\n",
       "      <td>137</td>\n",
       "      <td>127</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type 0  type 1  type 2  type 3  type 4  type 5  type 6  type 7  type 8  \\\n",
       "0      13       6       4       9       8      11       9      18      18   \n",
       "1      14      12      18      14      35      26      21      34      37   \n",
       "2       7       8      38      10      26      32      14      15      13   \n",
       "3       5       7       9       9       4       5      10      12      17   \n",
       "4      26       3      21      22      22      32       7      16      20   \n",
       "\n",
       "   type 9  ...  type 30  type 31  type 32  type 33  type 34  type 35  type 36  \\\n",
       "0      11  ...      171      170      184      182      198      175      183   \n",
       "1      21  ...       39       28       45       69       52       65       67   \n",
       "2      25  ...       63       66       63       64       61       57       72   \n",
       "3      20  ...       15       31       32       41       25       27       31   \n",
       "4      29  ...       51       50       62       58       54       55       96   \n",
       "\n",
       "   type 37  type 38  type 39  \n",
       "0      208      212      227  \n",
       "1       74       90       83  \n",
       "2       80       81       86  \n",
       "3       49       65       93  \n",
       "4      137      127      163  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"n_Data.csv\", sep=\",\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "automatic-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 20       # 예측할 seq 수\n",
    "\n",
    "type = [\"type %d\"%i for i in range(data.shape[1])]\n",
    "\n",
    "type_x = [\"type %d\"%i for i in range(data.shape[1]-seq)]\n",
    "type_y = [\"type %d\"%i for i in range(data.shape[1]-seq,data.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "subjective-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scale_cols = type\n",
    "df_scaled = scaler.fit_transform(data[scale_cols])\n",
    "\n",
    "df_scaled = pd.DataFrame(df_scaled)\n",
    "df_scaled.columns = scale_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "convertible-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_rate = 0.8\n",
    "sr = int(len(df_scaled) * split_rate)\n",
    "\n",
    "train = df_scaled[:sr]\n",
    "test = df_scaled[sr:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "interpreted-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, label, window_size = 40-seq):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        feature_list.append(np.array(data.iloc[i]))\n",
    "        label_list.append(np.array(label.iloc[i]))\n",
    "    \n",
    "    return np.array(feature_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "material-convertible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((320, 20, 1), (80, 20, 1))"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = type_x\n",
    "label_cols = type_y\n",
    "\n",
    "train_feature = train[feature_cols]\n",
    "train_label = train[label_cols]\n",
    "\n",
    "\n",
    "train_feature, train_label = make_dataset(train_feature, train_label, 40-seq)\n",
    "\n",
    "train_feature = train_feature.reshape(train_feature.shape[0],train_feature.shape[1],1)\n",
    "train_label = train_label.reshape(train_label.shape[0],train_label.shape[1],1)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_feature, train_label, test_size=0.2)\n",
    "\n",
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "relevant-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = test[feature_cols]\n",
    "test_label = test[label_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "answering-budget",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 20, 1), (100, 20, 1))"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature, test_label = make_dataset(test_feature,test_label)\n",
    "\n",
    "test_feature = test_feature.reshape(test_feature.shape[0],test_feature.shape[1],1)\n",
    "test_label = test_label.reshape(test_label.shape[0],test_label.shape[1],1)\n",
    "\n",
    "test_feature.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "framed-application",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(150,\n",
    "              input_shape=(train_feature.shape[1], train_feature.shape[2]),\n",
    "               activation='relu',\n",
    "               return_sequences=False)\n",
    "              )\n",
    "model.add(Dense(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "romance-battle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 150)               91200     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 20)                3020      \n",
      "=================================================================\n",
      "Total params: 94,220\n",
      "Trainable params: 94,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "uniform-monitoring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0753 - val_loss: 0.0924\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0560 - val_loss: 0.0474\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0426 - val_loss: 0.0402\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0393 - val_loss: 0.0373\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0365 - val_loss: 0.0355\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0339 - val_loss: 0.0349\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0326 - val_loss: 0.0327\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0290 - val_loss: 0.0292\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0268 - val_loss: 0.0302\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0259 - val_loss: 0.0258\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0206 - val_loss: 0.0220\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0202\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0190\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.0184\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0192\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0197\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.0190\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0182\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0170 - val_loss: 0.0184\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0175\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0187\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.0198\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0191\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0175\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.0171\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0184\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0162 - val_loss: 0.0173\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.0164\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.0171\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0190\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.0163\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0162\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0157 - val_loss: 0.0168\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0154 - val_loss: 0.0183\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.0164\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0157 - val_loss: 0.0161\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0154 - val_loss: 0.0161\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0155 - val_loss: 0.0165\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0154 - val_loss: 0.0161\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0151 - val_loss: 0.0168\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0152 - val_loss: 0.0159\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0162\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.0158\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0159\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.0164\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0181\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0160\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0156\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0161\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0153\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0157\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0189\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0154\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0174\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0182\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0150\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0139\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0135\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0144\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.0134\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0157\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0135\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0117\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0161\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0125\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0127\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0153\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0127\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0089\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0087\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0091\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.0091\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0076\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                   epochs=100,\n",
    "                   batch_size=20,\n",
    "                   validation_data=(x_valid, y_valid)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "divided-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "alike-meaning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20, 1)\n",
      "(100, 20)\n",
      "(100, 20)\n",
      "(100, 20)\n"
     ]
    }
   ],
   "source": [
    "print(test_feature.shape)\n",
    "\n",
    "test_feature = test_feature.reshape(test_feature.shape[0],test_feature.shape[1])\n",
    "\n",
    "test_label = test_label.reshape(test_label.shape[0],test_label.shape[1])\n",
    "\n",
    "print(test_feature.shape)\n",
    "\n",
    "print(test_label.shape)\n",
    "\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "finite-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d = pd.DataFrame(test_feature)\n",
    "pred_d = pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "traditional-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([test_d,pred_d],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "assisted-tragedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616490</td>\n",
       "      <td>0.640950</td>\n",
       "      <td>0.651138</td>\n",
       "      <td>0.727328</td>\n",
       "      <td>0.736348</td>\n",
       "      <td>0.715248</td>\n",
       "      <td>0.700122</td>\n",
       "      <td>0.820780</td>\n",
       "      <td>0.786591</td>\n",
       "      <td>0.805728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.325</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204160</td>\n",
       "      <td>0.226596</td>\n",
       "      <td>0.253827</td>\n",
       "      <td>0.289717</td>\n",
       "      <td>0.247481</td>\n",
       "      <td>0.301091</td>\n",
       "      <td>0.335429</td>\n",
       "      <td>0.381786</td>\n",
       "      <td>0.363564</td>\n",
       "      <td>0.413395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.150</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151158</td>\n",
       "      <td>0.165679</td>\n",
       "      <td>0.185350</td>\n",
       "      <td>0.204440</td>\n",
       "      <td>0.187958</td>\n",
       "      <td>0.203944</td>\n",
       "      <td>0.231858</td>\n",
       "      <td>0.263246</td>\n",
       "      <td>0.253680</td>\n",
       "      <td>0.279778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068156</td>\n",
       "      <td>0.095345</td>\n",
       "      <td>0.105358</td>\n",
       "      <td>0.111325</td>\n",
       "      <td>0.111101</td>\n",
       "      <td>0.127590</td>\n",
       "      <td>0.133391</td>\n",
       "      <td>0.148217</td>\n",
       "      <td>0.133231</td>\n",
       "      <td>0.153555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130201</td>\n",
       "      <td>0.143015</td>\n",
       "      <td>0.170534</td>\n",
       "      <td>0.185704</td>\n",
       "      <td>0.144783</td>\n",
       "      <td>0.170773</td>\n",
       "      <td>0.211040</td>\n",
       "      <td>0.241808</td>\n",
       "      <td>0.218609</td>\n",
       "      <td>0.254440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117978</td>\n",
       "      <td>0.118239</td>\n",
       "      <td>0.134497</td>\n",
       "      <td>0.130880</td>\n",
       "      <td>0.103274</td>\n",
       "      <td>0.135872</td>\n",
       "      <td>0.125005</td>\n",
       "      <td>0.141955</td>\n",
       "      <td>0.125502</td>\n",
       "      <td>0.125447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047070</td>\n",
       "      <td>0.035921</td>\n",
       "      <td>0.050925</td>\n",
       "      <td>0.030662</td>\n",
       "      <td>0.035961</td>\n",
       "      <td>0.035208</td>\n",
       "      <td>0.023574</td>\n",
       "      <td>0.035846</td>\n",
       "      <td>0.047157</td>\n",
       "      <td>0.022263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.425</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086668</td>\n",
       "      <td>0.094376</td>\n",
       "      <td>0.112770</td>\n",
       "      <td>0.125213</td>\n",
       "      <td>0.097602</td>\n",
       "      <td>0.120120</td>\n",
       "      <td>0.135529</td>\n",
       "      <td>0.155102</td>\n",
       "      <td>0.150984</td>\n",
       "      <td>0.165231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.975</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068250</td>\n",
       "      <td>0.060153</td>\n",
       "      <td>0.066742</td>\n",
       "      <td>0.045480</td>\n",
       "      <td>0.030550</td>\n",
       "      <td>0.073814</td>\n",
       "      <td>0.039428</td>\n",
       "      <td>0.039155</td>\n",
       "      <td>0.041824</td>\n",
       "      <td>0.003166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083338</td>\n",
       "      <td>0.084225</td>\n",
       "      <td>0.103068</td>\n",
       "      <td>0.097206</td>\n",
       "      <td>0.104603</td>\n",
       "      <td>0.101255</td>\n",
       "      <td>0.104542</td>\n",
       "      <td>0.123051</td>\n",
       "      <td>0.124568</td>\n",
       "      <td>0.129813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6   \\\n",
       "0   0.300  0.121212  0.028571  0.193548  0.157895  0.188679  0.125000   \n",
       "1   0.325  0.303030  0.428571  0.354839  0.868421  0.471698  0.339286   \n",
       "2   0.150  0.181818  1.000000  0.225806  0.631579  0.584906  0.214286   \n",
       "3   0.100  0.151515  0.171429  0.193548  0.052632  0.075472  0.142857   \n",
       "4   0.625  0.030303  0.514286  0.612903  0.526316  0.584906  0.089286   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "95  0.625  0.818182  0.828571  0.709677  0.421053  0.471698  0.214286   \n",
       "96  0.300  0.818182  0.742857  0.612903  0.157895  0.132075  0.250000   \n",
       "97  0.425  0.151515  0.314286  0.451613  0.684211  0.283019  0.321429   \n",
       "98  0.975  0.545455  0.514286  0.774194  0.368421  0.452830  0.428571   \n",
       "99  0.275  0.000000  0.542857  0.870968  0.315789  0.150943  0.303571   \n",
       "\n",
       "          7         8         9   ...        10        11        12        13  \\\n",
       "0   0.297872  0.265625  0.127273  ...  0.616490  0.640950  0.651138  0.727328   \n",
       "1   0.638298  0.562500  0.309091  ...  0.204160  0.226596  0.253827  0.289717   \n",
       "2   0.234043  0.187500  0.381818  ...  0.151158  0.165679  0.185350  0.204440   \n",
       "3   0.170213  0.250000  0.290909  ...  0.068156  0.095345  0.105358  0.111325   \n",
       "4   0.255319  0.296875  0.454545  ...  0.130201  0.143015  0.170534  0.185704   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "95  0.489362  0.296875  0.454545  ...  0.117978  0.118239  0.134497  0.130880   \n",
       "96  0.319149  0.281250  0.400000  ...  0.047070  0.035921  0.050925  0.030662   \n",
       "97  0.382979  0.281250  0.200000  ...  0.086668  0.094376  0.112770  0.125213   \n",
       "98  0.297872  0.375000  0.127273  ...  0.068250  0.060153  0.066742  0.045480   \n",
       "99  0.063830  0.265625  0.000000  ...  0.083338  0.084225  0.103068  0.097206   \n",
       "\n",
       "          14        15        16        17        18        19  \n",
       "0   0.736348  0.715248  0.700122  0.820780  0.786591  0.805728  \n",
       "1   0.247481  0.301091  0.335429  0.381786  0.363564  0.413395  \n",
       "2   0.187958  0.203944  0.231858  0.263246  0.253680  0.279778  \n",
       "3   0.111101  0.127590  0.133391  0.148217  0.133231  0.153555  \n",
       "4   0.144783  0.170773  0.211040  0.241808  0.218609  0.254440  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "95  0.103274  0.135872  0.125005  0.141955  0.125502  0.125447  \n",
       "96  0.035961  0.035208  0.023574  0.035846  0.047157  0.022263  \n",
       "97  0.097602  0.120120  0.135529  0.155102  0.150984  0.165231  \n",
       "98  0.030550  0.073814  0.039428  0.039155  0.041824  0.003166  \n",
       "99  0.104603  0.101255  0.104542  0.123051  0.124568  0.129813  \n",
       "\n",
       "[100 rows x 40 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "limiting-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = scaler.inverse_transform(df_scaled)\n",
    "prediction = scaler.inverse_transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "variable-willow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "       -64.96732885, -36.47093439, -49.62321353, -46.82424414,\n",
       "        -1.8263036 , -71.28379285, -40.79398251,   4.67440605,\n",
       "         1.6852476 ,   4.6142385 ,  -9.94568598,  -7.12145418,\n",
       "       -15.00647092,   2.83210492,  -4.75846362,   2.80527574,\n",
       "        -8.97070599,  -6.55037814,  -2.33996201,  -6.8707146 ])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]-actual[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "correct-proof",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.19966235047467\n"
     ]
    }
   ],
   "source": [
    "mse = 0.0\n",
    "for i in range(len(prediction)):\n",
    "    mse = mse +  sum((prediction[i]-actual[i]) ** 2)\n",
    "mse = mse / len(prediction)\n",
    "rmse = mse ** 0.5\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "fossil-squad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "oriental-merchandise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 1\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(actual[N] ,label='actual')\n",
    "plt.plot(prediction[N], label='prediction')\n",
    "plt.axis([0,40,0,250])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "mexican-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "dramatic-batch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_s1 = gaussian_filter1d(actual[0], sigma=3)\n",
    "y_s2 = gaussian_filter1d(actual[7], sigma=3)\n",
    "y_s3 = gaussian_filter1d(actual[51], sigma=3)\n",
    "y_s4 = gaussian_filter1d(actual[89], sigma=3)\n",
    "\n",
    "plt.figure(figsize=(3,2))\n",
    "plt.plot(y_s4, color='red')\n",
    "# plt.plot(actual[20])\n",
    "plt.axis([0,40,0,250])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "sharing-carter",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13.,   6.,   4.,   9.,   8.,  11.,   9.,  18.,  18.,  11.,   6.,\n",
       "        10.,  26.,  10.,  26.,  44.,  78.,  74., 119., 135., 190., 164.,\n",
       "       183., 179., 139., 194., 164., 159., 181., 181., 171., 170., 184.,\n",
       "       182., 198., 175., 183., 208., 212., 227.])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "pacific-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplot(2,2,1)\n",
    "# plt.plot(y_s1, color='red')\n",
    "# plt.xticks([0,20,40])\n",
    "# plt.yticks([0,50,100,150,200,250])\n",
    "# plt.show()\n",
    "\n",
    "# plt.subplot(2,2,2)\n",
    "# plt.xticks([0,40])\n",
    "# plt.yticks([0,50,100,150,200,250])\n",
    "# plt.plot(y_s2, color='red')\n",
    "\n",
    "# plt.subplot(2,2,3)\n",
    "# plt.xticks([0,40])\n",
    "# plt.yticks([0,50,100,150,200,250])\n",
    "# plt.plot(y_s3, color='red')\n",
    "\n",
    "# plt.subplot(2,2,4)\n",
    "# plt.xticks([0,20,40])\n",
    "# plt.yticks([0,50,100,150,200,250])\n",
    "# plt.plot(y_s4, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "static-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots(2,2,sharex=True,sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-layer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
